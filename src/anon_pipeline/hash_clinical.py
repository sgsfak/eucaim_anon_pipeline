from hashlib import md5
from pathlib import Path

import clevercsv
from loguru import logger


def hash_patient_id(patient_id: str, site_id: str) -> str:
    """
    Anonymizes the given patient ID according to the "CTP" algorithm.

    The hashed string is generated by concatenating the site ID and patient ID, hashing the
    result using the MD5 algorithm, and then truncating the result to the given maximum
    length. The hashed string is then prefixed with the given prefix.

    (see https://github.com/johnperry/CTP/blob/ea8639754cf38c50cdc9999170e192bd101fd5d7/source/java/org/rsna/ctp/stdstages/anonymizer/AnonymizerFunctions.java#L186)
    """
    if not patient_id:
        patient_id = "null"
    else:
        patient_id = patient_id.strip()

    # This method is used by the CTP anonymizer to hash patient IDs, and is included here to provide
    # compatibility with that system. Basically it computes the MD5 hash and then interprets the result
    # as an (big) integer in the "big endian" format.
    # (see https://github.com/johnperry/Util/blob/cf5a160b31abdc67f4767a932d70661257803320/source/java/org/rsna/util/DigestUtil.java#L91)
    s = f"[{site_id}]{patient_id}"
    h = md5(s.encode()).digest()
    return str(int.from_bytes(h, byteorder="big"))


def parse_and_hash_clinical_csv(
    input_file: Path,
    output_file: Path,
    site_id: str,
    prefix: str = "EUCAIM-",
) -> None:
    """
    Parses a clinical CSV file and hashes the patient IDs using the CTP algorithm.

    Args:
        input_file: The path to the input CSV file.
        output_file: The path to the output CSV file.
        site_id: The 'site ID' (actually "pepper") to use for hashing.
        prefix: The prefix to use for the hashed patient IDs, defaults to "EUCAIM-"
                Note that this should be aligned with the anon.script !!!

    Returns:
        None
    """
    logger.info(f"Parsing and hashing clinical CSV file {input_file}")
    with (
        open(input_file, "r", newline="") as fp,
        open(output_file, "w", newline="") as fp_out,
    ):
        dialect = clevercsv.Sniffer().sniff(fp.read(10000))
        if dialect is None:
            logger.error(f"Failed to detect CSV dialect for file {input_file}")
        logger.info(f"Detected CSV dialect: {dialect.to_dict()}")
        fp.seek(0)
        reader = clevercsv.reader(fp, dialect)
        rows = list(reader)

        # What will be the CSV dialect used for the output file? We have two sane options:
        # RFC4180, which is kind of standard, or the dialect used in the input file
        # I opted for RFC4180 to ensure consistency.
        # Note: For some reason in CleverCSV the 'excel dialect corresponds to RFC4180!
        # See https://clevercsv.readthedocs.io/en/latest/source/clevercsv.html#clevercsv.wrappers.write_table
        writer = clevercsv.writer(fp_out, "excel")

        # We assume that the first row in the input file contains the header, so
        # we write it to the output file as is:
        writer.writerow(rows[0])

        for row in rows[1:]:
            hashed_id = hash_patient_id(row[0], site_id)
            new_patient_id = f"{prefix}{hashed_id}"
            writer.writerow([new_patient_id, *row[1:]])
        logger.info(f"Wrote {len(rows)} rows to {output_file} in RFC4180 CSV format")
